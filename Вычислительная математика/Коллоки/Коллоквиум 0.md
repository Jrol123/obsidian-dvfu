Мы слишком молоды для этого дерьма (пока что)

## 1.	Подчиненные матричные нормы. Свойства. Формула для вычисления второй нормы матрицы.

**Подчинённая матричная норма**
	Норма, которая удовлетворяет условию $||A|| = \underset{x \neq 0}{\sup} \dfrac{||A{x}||}{||x||}$
**Свойства**
1. $||E|| = 1$
2. $||AB|| \le ||A|| \cdot ||B||$

**Вторая матричная норма**
$||A||_{2} = \sqrt{\max_{i} \lambda_{i} \sum \limits_{i = 1}^n A^T A}$

## 2.	Подчиненные матричные нормы. Свойства. Формула для вычисления третьей нормы матрицы.

**Подчинённая матричная норма**
	Норма, которая удовлетворяет условию $||A|| = \underset{x \neq 0}{\sup} \dfrac{||A{x}||}{||x||}$
**Свойства**
1. $||E|| = 1$
2. $||AB|| \le ||A|| \cdot ||B||$

**Третья матричная норма**
Просто распиши p норму, лол

## 3.	Согласованные матричные нормы.

**Согласованная матричная норма**
	$||Ax||\le||A||\cdot||x||$
Что-то как-то инфы по нулям у меня
## 4.	Число обусловленности матрицы. Определение. Вычислительная формула. Пример плохо обусловленной системы.

**Число обусловленности матрицы $A$**.
	Число, показывающее, насколько может измениться значение функции при небольшом изменении аргумента.
	$\mu(A) = \underset{ y \neq 0 }{ \underset{ x \neq 0 }{ sup } }\left(\dfrac{||Ax||}{||x||} / \dfrac{||Ay||}{||y||}\right)$

**Вычислительная формула**
	$\mu(A) = ||A||\cdot ||A^{-1}||$

**Вывод**
	$\mu(A) = \underset{ y \neq 0 }{ \underset{ x \neq 0 }{ sup } }\left(\dfrac{||Ax||}{||x||} / \dfrac{||Ay||}{||y||}\right) = (\underset{ x \neq 0 }{ \sup }\dfrac{||Ax||}{||x||} / \underset{ y \neq 0 }{ \inf }\dfrac{||Ay||}{||y||})=$
	$z=Ay\implies y=A^{-1}z$
	$=\dfrac{||A||}{\inf\limits_{z\neq 0}\dfrac{||z||}{||A^{-1}z||}}=\dfrac{||A||}{\dfrac{1}{\sup\limits_{z\neq 0}\dfrac{||A^{-1}z||}{||z||}}}=\dfrac{||A||}{\dfrac{1}{||A^{-1}||}}=||A||\cdot ||A^{-1}||$

**Плохо обусловленная матрица**
	$A=\begin{pmatrix}\mathsf{1}&&\mathsf{1}\\\mathsf{1}&&\mathsf{1.01}\end{pmatrix}$
	Оставлю вычисление $\mathsf{cond(A)}$ читателю в качестве несложного упражнения
	P. S. Там что-то около 400

## 5.	Метод Гаусса.

Ебал я это оформлять

## 6.	LU – разложение. Необходимое и достаточное условие существования.

**LU - разложение**
	Декомпозиция матрицы системы $A$ на две треугольные матрицы $L, U$ так, что бы $A=L\cdot U$
	$$A=
	\begin{pmatrix}
	{a_{11}} && {a_{12}} && {\ldots} && {a_{1n}} \\
	{a_{21}} && {a_{22}} && {\ldots} && {a_{2n}} \\
	{\ldots} && {\ldots} && {\ldots} && {\ldots} \\
	{a_{n1}} && {a_{n2}} && {\ldots} && {a_{nn}} 
	\end{pmatrix}$$
	$$
	\quad L =
	\begin{pmatrix}
	{1} && {0} && {\ldots} && {0} \\
	{l_{21}} && {1} && {\ldots} && {0} \\
	{\ldots} && {\ldots} && {\ldots} && {\ldots} \\
	{l_{n1}} && {l_{n2}} && {\ldots} && {1} 
	\end{pmatrix}
	\quad U=
	\begin{pmatrix}
	{d_{11}} && {d_{12}} && {\ldots} && {d_{1n}} \\
	{0} && {d_{22}} && {\ldots} && {d_{2n}} \\
	{\ldots} && {\ldots} && {\ldots} && {\ldots} \\
	{0} && {0} && {\ldots} && {d_{nn}} 
	\end{pmatrix} 
	$$
	
Дальше надо перемножить матрицы и вывести общие формулы для элементов
Но я с этим ебаться сейчас не хочу

**Необходимое и достаточное условие существования**
	Что-то там что все главные миноры не 0, помоему
## 7.	Метод квадратного корня.
**Метод квадратного корня**
	Частный случай $LU$ разложения для симметричных матриц $(A=A^T)$
	Где-то здесь будет описание метода 

## 8.	Матрица отражения, ее свойства.
**Определение**
	Пусть $p\in R^n-$ вектор нормали некоторой гиперплоскости в $R^n$, проходящей через $\theta$
	Тогда $y=x-2\dfrac{(p, x)}{(p, p)}p~-$ задает вектор $y$, отраженный к $x$ относительно гиперплоскости $(p, x)=0$
	Проведем ряд преобразований:
	$y=x-2\dfrac{(p, x)}{(p, p)}p=x-\dfrac{2}{(p, p)}\cdot(p,x)\cdot p=x-\dfrac{2}{(p, p)}\cdot p \cdot p^T \cdot x=(E-\dfrac{2}{(p, p)}\cdot p \cdot p^T)\cdot x$
	Обозначим $P=E-\dfrac{2}{(p, p)}\cdot p \cdot p^T$
	Тогда $P~-$ матрица отражения

**Свойства**
1. $P^2=E$
2. $P^T=P$
3. $P^T\cdot P = P^2=E\implies P-$ ортогональная матрица
4. При замене нормали $p=\beta\cdot p$ матрица отражения не изменится
5. $p=x-y$
6. $p_i=0\implies y_i = x_i \quad i=\overline{1,k}$
7. $\begin{cases}{p_1=\ldots=p_k=0}\\ {x_{k+1}=\ldots=x_n=0}\end{cases}\implies y_{k+1}=\ldots=y_n=0$

## 9.	QR – разложение. Условие существования QR – разложения.

Везде, где деление, знаменатель не ноль
Ну а вообще все сводится к тому, что разложение есть всегда(если матрица невырожденая)

## 10.	Метод окаймления обращения матриц.
А это надо гуглить
Юху!
Буду сегодня перед сном смотреть на матрицы...
