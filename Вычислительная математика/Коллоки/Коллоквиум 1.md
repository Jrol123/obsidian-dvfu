# 1.	Двухслойные итерационные методы. Погрешность. Невязка. Матрица перехода. Асимптотическая скорость сходимости.

**Итерационные методы**
	Методы, задающие последовательность векторов $x^{(k)}:\lim\limits_{k\to \infty}\| x^{(k)}-x^* \|=0$
		$x^{*}$ - решение
**Канонический вид двухслойного итерационного метода**
	$B\dfrac{x^{(k+1)}-x^{(k)}}{\tau_{k+1}} +Ax^{(k)} = f$
		$f = Ax^{*}$
*Другая запись*
	$Bx^{(k+1)}=(B-\tau_k A)x^{(k)}+\tau f$
*Замечание*
	При $\tau_k=\tau ~\forall k$ метод называется **стационарным**

**Двухслойность**
	Означает, что функция зависит только от $x^{(k)}$ и не зависит от остальных приближений к решению.

**Погрешность**
	Разница между $k$-ой итерацией и точным решением
	$z^{(k)}=x^{(k)}-x^*$

**Невязка**
	$r^{(k)}=Ax^{(k)} - f$

**Матрица перехода**
	$S=E-\tau B^{-1}A$
**Вывод**
	$B\dfrac{x^{(k+1)}-x^{(k)}}{\tau} +Ax^{(k)} = f$
	$B\dfrac{x^{(k+1)}-x^{*}-(x^{(k)}-x^{*})}{\tau} +Ax^{(k)}- Ax^{*}= 0$
	$B\dfrac{z^{(k+1)}-z^{(k)}}{\tau} +Az^{(k)}= 0$
	$Bz^{(k+1)}-Bz^{(k)}= -\tau Az^{(k)}$
	$z^{(k+1)}= (E-\tau B^{-1}A)z^{(k)}$
	$z^{(k+1)}= Sz^{(k)}$

**Асимптотическая скорость сходимости**
	$R=-\ln \| S \|$
**Вывод**
	Найдем k удовлетворяющий неравенству $\|x^{(k)}\|\le \dfrac 1 e \|x^{(0)}\|$
	Так как $z^{(k)}=S^kz^{(0)}$, то для этого достаточно $\|S\|^k\le\dfrac 1 e\iff k\ln \|S\|\le-1$
	Так как $\|S\|\le0\implies k\ge \dfrac 1 {-\ln\|S\|}$

# 2.	Критерий сходимости двухслойного итерационного процесса.
**Критерий сходимости**
	Итерационный процесс сходится при любом начальном приближении $\iff |\lambda_i(S)|<1~\forall i$ 
**Доказательство**
	$(\implies)$
		Итерационный процесс сходится при любом начальном приближении
		Предположим, что $\exists \lambda_i(S):|\lambda_i|\ge 1$
		Пусть этому сз соответствует собственный вектор $u$
		Тогда возьмем $x^{(0)}=x^* + u$
		$z^{(0)}=u$
		$z^{(k)}=S^k z^{(0)}=S^k u =\lambda_i^k u$
		$\|z^{(k)}\|=\|\lambda_i^k u\|=|\lambda_i|^k \|u\|\quad u\neq \theta$
		$\lim\limits_{k\to\infty} \|z^{(k)}\| \neq 0$
		Получили противоречие
	$(\impliedby)$
		Чтобы получить доказательство необходимости позвоните на номер 8 423 439 85 47 и попросите там

# 3.	Достаточное условие сходимости двухслойного итерационного процесса.
**Достаточное условие сходимости**
	Итерационный процесс сходится при любом начальном приближении $\impliedby$
	$\exists$ матричная норма, согласованная с некоторой векторной$:\|S\|<1$
**Доказательство**
	Пусть $\|S\|<1$
	$u-$ собственный вектор для $\lambda$
	$|\lambda|\cdot \|u\|=\|\lambda\cdot u\|=\|S\cdot u \|$
	В силу согласованности $\|S\cdot u\| \le \|S\|\cdot \|u\|$
	$|\lambda|\le \|S\|<1$
	Тогда выполняется критерий сходимости двухслойного итерационного процесса

# 4.	Метод простой итерации. (Для симметрической, положительно определенной матрицы). Оптимальный шаг.
**Метод простой итерации**
	Двухслойный итерационный стационарный метод при $B=E$
	$S=E-\tau A$
	$x^{(k+1)} = x^{(k)} -\tau(Ax^{(k)} - f)$
**Оптимальный шаг**
	$\tau_0=\dfrac{2}{\alpha+\beta}$
**Доказательство**
	Найдем оптимальный $\tau_0 = argmax(R) =argmax(-\ln \|S\|)=argmin(\|S\|)$
	Пусть $A=A^T>0$ тогда все $\lambda_i>0 \in R$
	$\alpha =\min(\lambda_i) \quad \beta =\max(\lambda_i)$
	Будем использовать $\|S\|_2=\max \lambda_i (S)$
	$\lambda_i(S)=1-\tau \lambda_i (A)$
	Рассмотрим функцию $f(\tau, \lambda)=|1-\tau \lambda|$
	$\max\limits_{\alpha \le \lambda \le \beta}f(\tau,\lambda)=\max(f(\tau, \alpha), f(\tau, \beta))$
	Очевидно, что
	$\max\limits_{1\le i \le n} f(\tau,\lambda_i) \le \max\limits_{\alpha \le \lambda \le \beta} f(\tau,\lambda)$ и
	$\max\limits_{1\le i \le n} f(\tau,\lambda_i) \ge \max(f(\tau, \alpha), f(\tau, \beta))$
	$\implies \|S\|_2 = \max\limits_{1\le i \le n} f(\tau,\lambda_i) = \max(f(\tau, \alpha), f(\tau, \beta))$
	Покажем, что $\tau_0=\dfrac{2}{\alpha+\beta}$
	$1-\tau_0 \alpha = \dfrac{\beta - \alpha}{\alpha + \beta}>0$
	$1-\tau_0 \beta = \dfrac{\alpha - \beta}{\alpha + \beta}<0$
	$\|S\|_2 = \dfrac{\beta - \alpha}{\alpha + \beta}$
	Пусть $\tau < \tau_0$
	$1-\tau \alpha > 1 - \tau_0 \alpha=\dfrac{\beta - \alpha}{\alpha + \beta}$
	$\max(f(\tau, \alpha), f(\tau, \beta))\ge f(\tau, \alpha)=|1-\tau \alpha|>\dfrac{\beta - \alpha}{\alpha + \beta}$
	$\|S\|_2 > \dfrac{\beta - \alpha}{\alpha + \beta}$
	Следовательно, по асимптотической скорости сходимости, это не оптимальный шаг
	Аналогично для $\tau > \tau_0$

**Асимптотическая скорость сходимости**
	$R=-\ln \dfrac{\beta - \alpha}{\alpha + \beta}$

# 5.	Метод Якоби. Теорема Адамара.
**Метод Якоби**
	Двухслойный итерационный стационарный метод при $B=D$
	$A=A_L + D + A_U \quad D=diag(a_{11}, a_{22}, \ldots ,a_{nn})$
	$\tau=1$
	$Dx^{(k+1)}-Dx^{(k)} +(A_L+D+A_U)x^{(k)} = f$
	$Dx^{(k+1)}=f-(A_L+A_U)x^{(k)}$
	**Скалярный вид:**
		$a_{ii}x_i^{(k+1)}=f_i-\sum\limits_{j=1,i\neq j}^n a_{ij}x_j^{(k)}$
	**Матрица перехода:**
		$S=E-D^{-1}A=E-D^{-1}(A_L+D+A_U)=-D^{-1}(A_L+A_U)$

**Строгое условие Адамара**
	$\left| a_{ii} \right| \gt \sum \limits_{ j\neq i }^{ n } \left| a_{ij} \right|$
**Теорема Адамара**
	Матрица со строгим условием Адамара не вырождена
**Доказательство**
	Пусть $\det A = 0$
	Тогда $Ax=0$ - имеет ненулевое решение
	Пусть $|x_k|=\max x_i > 0$ 
	Возьмём $k$-е уравнение системы $Ax = 0$
	$a_{kk}x_k+\sum\limits_{j=1, j \neq k}^{n}a_{kj}x_j=0$
	$a_{kk}x_k=-\sum\limits_{j=1, j \neq k}^{n}a_{kj}x_j$
	$|a_{kk}||x_k|\le \sum\limits_{j=1, j \neq k}^{n}|a_{kj}||x_j|\le |x_k|\sum\limits_{j=1, j \neq k}^{n}|a_{kj}|$
	$|a_{kk}| \le \sum\limits_{j=1 \neq k}^{n}|a_{kj}|$
	Получили противоречие.
	ч. т. д.

# 6.	Метод Якоби. Теорема Гершгорина.
**Метод Якоби**
	Двухслойный итерационный стационарный метод при $B=D$
	$A=A_L + D + A_U \quad D=diag(a_{11}, a_{22}, \ldots ,a_{nn})$
	$\tau=1$
	$Dx^{(k+1)}-Dx^{(k)} +(A_L+D+A_U)x^{(k)} = f$
	$Dx^{(k+1)}=f-(A_L+A_U)x^{(k)}$
	**Скалярный вид:**
		$a_{ii}x_i^{(k+1)}=f_i-\sum\limits_{j=1,i\neq j}^n a_{ij}x_j^{(k)}$
	**Матрица перехода:**
		$S=E-D^{-1}A=E-D^{-1}(A_L+D+A_U)=-D^{-1}(A_L+A_U)$

**Теорема Гершгорина**
	$\forall \lambda(A) \quad |\lambda-a_{ii}|\le \sum\limits_{j=1, j\neq i}^{n}|a_{ij}|$
**Доказательство**
	$A - \lambda E$ - вырожденная матрица.
	Следовательно, по теореме Адамара $\exists k : \left| a_{kk} - \lambda \right| \leq \sum \limits_{ j=1, j \neq k }^{ n } \left| a_{kj} \right|$
	P. S. В модуле разницы можно переставлять местами числа

# 7.	Метод Якоби. Достаточное условие сходимости.
**Метод Якоби**
	Двухслойный итерационный стационарный метод при $B=D$
	$A=A_L + D + A_U \quad D=diag(a_{11}, a_{22}, \ldots ,a_{nn})$
	$\tau=1$
	$Dx^{(k+1)}-Dx^{(k)} +(A_L+D+A_U)x^{(k)} = f$
	$Dx^{(k+1)}=f-(A_L+A_U)x^{(k)}$
	**Скалярный вид:**
		$a_{ii}x_i^{(k+1)}=f_i-\sum\limits_{j=1,i\neq j}^n a_{ij}x_j^{(k)}$
	**Матрица перехода:**
		$S=E-D^{-1}A=E-D^{-1}(A_L+D+A_U)=-D^{-1}(A_L+A_U)$
	
**Достаточное условие сходимости**
	Если для матрицы $A$ выполняется строгое условие Адамара, то метод Якоби сходится при любом начальном приближении
**Доказательство**
	По [[#6. Метод Якоби. Теорема Гершгорина.|теореме Гершгорина]] $|\lambda(S)|=|\lambda(S)-0|\le \sum\limits_{j=1, j\neq i}^{n}\left| \dfrac{a_{ij}}{a_{ii}} \right|\le \dfrac{1}{|a_{ii}|}\sum\limits_{j=1, j\neq i}^{n}| a_{ij}|\le \dfrac{|a_{ii}|}{|a_{ii}|}=1$
	Выполняется критерий сходимости
# 8.	Метод Зейделя (метод полной релаксации). Достаточное условие сходимости.
**Метод Зейделя**
	Называется методом полной релаксации, из-за обнуления $i$-й компоненты невязки.
	Двухслойный итерационный стационарный метод при $B=A_L+D$
	$A=A_L + D + A_U \quad D=diag(a_{11}, a_{22}, \ldots ,a_{nn})$
	$\tau=1$
	$(A_L+D)x^{(k+1)}-(A_L+D)x^{(k)} +(A_L+D+A_U)x^{(k)} = f$
	$Dx^{(k+1)}=f-A_Ux^{(k)}-A_Lx^{(k+1)}$
	**Скалярный вид:**
		$a_{ii}x_i^{(k+1)}=f_i-\sum\limits_{j=i+1}^n a_{ij}x_j^{(k)}-\sum\limits_{j=1}^{i-1} a_{ij}x_j^{(k+1)}$
	**Матрица перехода:**
		$S=E-(A_L+D)^{-1}A=E-(A_L+D)^{-1}(A_L+D+A_U)=-(A_L+D)^{-1}A_U$

**Критерий сходимости**
	Из критерия сходимости итерационного процесса не сложно показать, что метод сходится при любом начальном приближении $\iff |\lambda|<1  \ \ \forall \lambda$ и $\det(\lambda(A_L+D)+A_U) = 0$
		$\det \left( -\left( A_{L} + D \right)^{-1}A_{U} - \lambda E \right) = 0$
		$\det \left( -\left( A_{L} + D \right)^{-1}\left( A_{U} + \lambda \left( A_{L} + D \right) \right) \right) = 0$
		$\det \left( -\left( A_{L} + D \right)^{-1} \right)\cdot \det \left( A_{U} + \lambda \left( A_{L} + D \right) \right) = 0$
		Так как $\det \left( -\left( A_{L} + D \right)^{-1} \right)\neq 0$, то:
		$\det \left( A_{U} + \lambda\left( A_{L} + D \right) \right) = 0$
		

**Достаточное условие сходимости**
	Если для матрицы $A$ выполняется строгое условие Адамара, то метод Зейделя сходится при любом начальном приближении
**Доказательство**
	Если матрица вырожденная, то существует строка $k$, в которой условие Адамара не выполняется.
	$\det(\lambda(A_L+D)+A_U)=0\implies\exists k: |\lambda||a_{kk}|=|\lambda a_{kk}|\le \sum\limits_{j=1}^{k-1}|\lambda||a_{kj}|+\sum\limits_{j=k+1}^{n}|a_{kj}|$
	$|\lambda| \left(|a_{kk}|- \sum\limits_{j=1}^{k-1}|a_{kj}|\right)\le\sum\limits_{j=k+1}^{n}|a_{kj}|$
	Также по условию знаем, что $|a_{kk}|> \sum\limits_{j=1}^{k-1}|a_{kj}|+\sum\limits_{j=k+1}^{n}|a_{kj}|\implies |a_{kk}|- \sum\limits_{j=1}^{k-1}|a_{kj}|>\sum\limits_{j=k+1}^{n}|a_{kj}|$
	Получаем оценку $|\lambda|<1$
	Выполняется критерий сходимости

# 9.	Метод последовательной верхней релаксации. Матрица перехода.
**Метод последовательной верхней релаксации**
	В отличие от метода Зейделя, будет проводиться не обнуление невязки $r_{i}$, а лишь уменьшения $\left| r_{i} \right|$, по сравнению с $\left| t_{i} \right|$
		$t_{z} \quad z = \left( x_{1}^{(k + 1)}, \ldots, x_{i - 1}^{(k + 1)}, x_{i}^{(k + 1)}, x_{i + 1}^{(k)}, \ldots, x_{n}^{(k)} \right)$
		$r_{y} \quad y = \left( x_{1}^{(k + 1)}, \ldots, x_{i - 1}^{(k + 1)}, x_{i}^{(k)}, \ldots, x_{n}^{(k)} \right)$
	Пусть $\left| r_{i} \right| = \left| t_{i} - \alpha a_{ii} \right| < \left| t_{i} \right|$, где $\alpha = x^{{(k)}} - x^{(k + 1)}$
	$\left| \alpha - \dfrac{t_{i}}{a_{ii}} \right| < \left| \dfrac{t_{i}}{a_{ii}} \right|$
	Если $\dfrac{t_{i}}{a_{ii}} > 0$, то $0 < \alpha < 2 \dfrac{t_{i}}{a_{ii}}$.
	Если $\dfrac{t_{i}}{a_{ii}} < 0$, то $0 > \alpha > 2 \dfrac{t_{i}}{a_{ii}}$
	Пусть $\alpha = \omega \dfrac{t_{i}}{a_{ii}}$, где $\omega \in \left( 0, 2 \right)$
	**Тогда** $r_{i} = t_{i} - a_{ii}\omega\dfrac{t_{i}}{a_{ii}} = t_{i}\left( 1 - \omega \right)$
		Как видим, будет происходить уменьшение компоненты невязки $\left| r_{i} \right| < \left| t_{i} \right|$
	При $\omega = 1,\ r_{i} = 0$
		При $0 < \omega < 1$ - верхний метод
		При $1 < \omega < 2$ - нижний метод
	Получаем: $B = D + \omega A_{L} \quad \tau = \omega$
	**Скалярный вид:**
		$x_{i}^{(k + 1)} = \left[ \omega f_{i} - \omega \sum \limits_{ j=1 }^{ i - 1 }a_{ij}x_j^{(k + 1)} - \omega \sum \limits_{ j=i + 1 }^{ n }a_{ij}x_{j}^{(k)} + \left( 1 - \omega \right)x_{i}^{(k)}a_{ii} \right]\dfrac{1}{a_{ii}}$
	**Каноническая форма:**
		$\left( D + \omega A_{L} \right)\dfrac{x^{(k + 1)} - x^{(k)}}{\omega} + Ax^{(k)} = f$
	**Матрица перехода:**
		$S = E - \omega \left( D + \omega A_{L} \right)$

**Достаточное условие сходимости**
	Для симметричных, положительно определённых матриц метод сходится, если $\omega \in \left( 0, 2 \right)$

# 10.	Метод наискорейшего градиентного спуска. ~

**Метод наискорейшего градиентного спуска**
	Есть метод градиентного спуска, где $x^{(k + 1)} = x^{(k)} - \delta_{k}\nabla F(x^{(k)})$