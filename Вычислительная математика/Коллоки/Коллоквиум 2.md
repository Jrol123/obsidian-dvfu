# 1. Проблема собственных значений. Устойчивость
## Проблема собственных значений
**Полная проблема**
	Нахождение всех собственных значений и собственных векторов некоторой матрицы
**Частичная проблема собственных значений**
	Нахождение нескольких собственных значений и соответствующих им векторов
## Устойчивость
Устойчивость это то, насколько сильно меняются собственные значения и собственные векторы при небольших изменениях в исходной матрице.
A. k. a. [[Коллоквиум 0#4. Число обусловленности матрицы. Определение. Вычислительная формула. Пример плохо обусловленной системы.|Число обусловленности]]

# 2. Вариационное описание собственных значений симметрической матрицы
## Условия
Пусть $\lambda_{i}(A) \gt 0$ и $\lambda_{1}(A) \leq \lambda_{2}(A) \leq \ldots \leq \lambda_{n}(A)$
Пусть $y = U^{T}x$
$\dfrac{\left( Ax, x \right)}{(x, x)} = \dfrac{\left( UDU^{T}x, x \right)}{(x, x)} = \dfrac{\left( DU^{T}x, U^{T}x \right)}{\left( U^{T}x, U^{T}x \right)} = \dfrac{\left( Dy, y \right)}{\left( y, y \right)}$
В силу невырожденности $U$: 
$\underset{ x \neq 0 }{ \min } \dfrac{\left( Ax, x \right)}{\left( x, x \right)} = \underset{ y \neq 0 }{ \min } \dfrac{\left( Dy, y \right)}{\left( y, y \right)}$
$U$ - ортогональная матрица, где $u^{(i)}$ - собственный вектор
$D$ - диагональная матрица, где $d^{(i)} = \lambda_{i}(A)$

## Вариационное описание
**Отношение Рэлея**
	$R(A, x) = \dfrac{\left( Ax, x \right)}{(x, x)} = \dfrac{x^{T}Ax}{x^{T}x}$
**Вариационное описание**
	$\lambda_{1}(A) \leq \lambda_{2}(A) \leq \ldots \leq \lambda_{n}(A)$
	$\underset{ \begin{matrix}x \neq 0 \\ \left( x, u^{(1)} \right) = 0 \\ \ldots \\ \left( x, u^{(i - 1)} \right)\end{matrix} }{ \min } \dfrac{\left( Ax, x \right)}{\left( x, x \right)} = \lambda_{i}(A) \quad i = 1, 2, \ldots, n$

## Доказательство

Покажем, что $\underset{ y \neq 0 }{ \min } \dfrac{\left( Dy, y \right)}{\left( y, y \right)} = \lambda_{1}(A)$, где $\lambda_{1} - \min$
$\dfrac{\left( Dy, y \right)}{\left( y, y \right)} = \dfrac{\sum \limits_{ i=1 }^{ n }\lambda_{i}\left( A \right)y_{i}^{2}}{\sum \limits_{ i=1 }^{ n }y_{i}^{2}} \geq \dfrac{\sum \limits_{ i=1 }^{ n }\lambda_{1}\left( A \right)y_{i}^{2}}{\sum \limits_{ i=1 }^{ n }y_{i}^{2}} = \lambda_{1}(A)$
Тогда
$y = e_{1} = \begin{pmatrix}1 \\ 0 \\ \vdots \\ 0\end{pmatrix}$
$\dfrac{\left( De_{1}, e_{1} \right)}{\left( e_{1}, e_{1} \right)} = \dfrac{\lambda_{1}(A)}{1}$
Очевидно, что минимальное значение отношения Рэлея достигается при $x = Ue_{1}$

Добавим условие $\left( x, u^{(1)} \right) = 0$
$\underset{ \begin{matrix}x \neq 0 \\ \left( x, u^{(1)} = 0 \right)\end{matrix}}{ \min } \dfrac{\left( Ax, x \right)}{\left( x, x \right)} = \underset{ \begin{matrix}y \neq 0 \\ \left( y, e_{1} = 0 \right)\end{matrix} }{ \min } \dfrac{\left( Dy, y \right)}{\left( y, y \right)}$
Получим, что $y_{1} = 0$. Поэтому для всех $y$, где $y \neq 0$ и $\left( y, e_{1} \right) = 0$
$\dfrac{\left( De_{1}, e_{1} \right)}{\left( e_{1}, e_{1} \right)} = \dfrac{\sum \limits_{ i = 2 }^{ k }\lambda_i(A)y_{i}^{2}}{\sum \limits_{ i = 2}^{ k }y_{i}^{2}} \geq \lambda_{2}(A)$
И если взять $y = e_{2} = \begin{pmatrix}0 \\ 1 \\ \vdots \\ 0\end{pmatrix}$, то получим:
$\underset{ \begin{matrix}x \neq 0 \\ \left( x, u^{(1)} = 0 \right)\end{matrix}}{ \min } \dfrac{\left( Ax, x \right)}{\left( x, x \right)} = \underset{ \begin{matrix}y \neq 0 \\ \left( y, e_{1} = 0 \right)\end{matrix} }{ \min } \dfrac{\left( Dy, y \right)}{\left( y, y \right)} =\lambda_{2}$

# 3. Вариационный принцип Куранта-Фишера~
## Вариационный принцип Куранта-Фишера
$\underset{ R_{n - i + 1} }{ \max }\underset{ \begin{matrix}x \neq 0 \\ x \in R_{n - i + 1}\end{matrix} }{ \min } \dfrac{\left( Ax, x \right)}{\left( x, x \right)} = \lambda_{i}(A) \quad i = 1, 2, \ldots, n$
## Доказательство
Покажем, что если $S_{i}$ - подпространство, порождённое собственными векторами $u^{(1)}, \ldots, u^{(i)}$, то для всех $x \neq 0 \in S_{i}$:
$\dfrac{\left( Ax, x \right)}{\left( x, x \right)} \leq \lambda_{i}(A)$

Т. к. $x \in S_{i}$, то $x = \sum \limits_{ j = 1 }^{ i }c_{j}u^{(j)}$

$\left( x, x \right) = \sum \limits_{ j = 1 }^{ i }c_{j}^{2} \quad \left( Ax, x \right) = \sum \limits_{ j = 1 }^{ i }\lambda_{j}(A)c_{j}^{2}$
$\dfrac{\left( Ax, x \right)}{\left( x, x \right)} = \dfrac{\sum \limits_{ j = 1 }^{ i }\lambda_{j}\left( A \right)c_{j}^{2}}{\sum \limits_{ j = 1 }^{ i }}$

# 4. Два следствия из вариационного принципа Куранта-Фишера~
## Следствие 1
Пусть $A = A^{T},\ B = B^{T}$
$\lambda_{1}(A) \leq \lambda_{2}(A) \leq \ldots \leq \lambda_{n}(A)$
$\lambda_{1}(B) \leq \lambda_{2}(B) \leq \ldots \leq \lambda_{n}(B)$
И пусть для всех $x$ выполняется:
$\left( Ax, x \right) \leq \left( Bx, x \right)$
Тогда:
$\lambda_{i}(A) \leq \lambda_{i}(B)$
## Доказательство следствия 1
## Следствие 2
## Доказательство следствия 2
# 5. Метод вращения решения проблем собственных значений. Типичный шаг метода

Для всякой симметрической матрицы $A$ существует такая ортогональная матрица $U$, что 
$U^T A U = \Lambda$
, где $\Lambda$ - диагональная матрица. При этом диагональные элементы матрицы $\Lambda$ являются собственными значениями, а столбцы матрицы $U$ - собственными векторами матрицы $A$. 
Метод вращений состоит в построении таких ортогональных матриц $U_k$, что последовательность $A_{k+1} = U_k^T A U_k$ при $k \to \infty$ стремится к диагональной матрице $\Lambda$. 
Каждая $U_k$ в этом методе представляет собой произведение $k$ матриц вращений, имеющих вид:
$$ C_{lm} = \begin{pmatrix}1 &0&&&&&&& 0 \\ 0& \dots &&&&&&0 \\ && c && \ldots  & & -s\\ && \vdots & 1 &&&\vdots \\ &&&& \ldots && \\ &&\vdots &&& 1 &\vdots \\ &&s &&\ldots && c \\ & 0 & &&&&&\ldots & 0 \\ 0 &&&&&&& 0 & 1 \end{pmatrix} \begin{matrix}\\- \  l\text{-ая строка} \\\\\\\\\\ - \ m\text{-ая строка} \\\\  \end{matrix}$$
Параметры $c, s$, определяющие матрицу $C_{ij}$, называются опорными элементами и удовлетворяют равенству $s^2 + c^2 = 1$. 
Из этого свойства опорные элементы можно интерпретировать как синус и косинус от определённого угла $\phi$: $s = \sin \phi, c = \cos \phi$.
Матрица $C_{lm}$ является ортогональной, так как $C_{lm}^T C_{lm} = C_{lm} C_{lm}^T = E$.

## Типичный шаг метода вращений
Находим максимальный по модулю элемент матрицы $A$ вне главной диагонали и зафиксируем его индексы $l, m \ (l \ne m)$:
   $|a_{lm}| = \underset{i \ne j}\max |a_{ij}|$ 
   
Построим матрицу вращений, пока не определяя конкретные значения опорных элементов. 
Положим $B = C_{lm}^T A C_{lm}$, причём данная матрица будет являться симметричной:
$B^T = (C_{lm}^T A C_{lm})^T = C_{lm}^T A^T (C_{lm}^T)^T = C_{lm}^T A C_{lm} = B$ 
 
Получим формулы для опорных элементов. Для этого достаточно рассмотреть только верхнюю или нижнюю половину элементов от главной диагонали (т. к. матрица $B$ симметричная). 
Обозначим $D = A C_{lm}$.
Тогда $B = C_{lm}^T D$.

Так как у матрицы $C_lm$ отличаются только $l$-ый и $m$-ый столбцы от столбцов соответствующей единичной матрицы, то  $l$-ый и $m$-ый столбцы будут отличатся у матрицы $D$ от столбцов матрицы $A$.
$\begin{matrix}d_{il} = ca_{il} + sa_{im} \\ d_{im} = -sa_{il} + ca_{im}\end{matrix} \quad i = \overline{1, n}$

Так как у матрицы $C_{lm}^T$ только $l$-ая и $m$-ая строки отличаются от соответствующих строк единичной матрицы, то у матрицы $B$ будут отличатся только $l$-ая и $m$-ая строки от соответствующих строк матрицы $D$:
$\begin{matrix}b_{li} = cd_{li} + sd_{mi} \\ b_{mi} = -sd_{li} + cd_{mi}\end{matrix} \quad i = \overline{1, n}$

При $i \ne l$ и $i \ne m \quad d_{li} = a_{li}, d_{mi} = a_{mi}$, следовательно
$\begin{matrix}b_{li} = ca_{li} + sa_{mi} \\ b_{mi} = -sa_{li} + ca_{mi}\end{matrix} \quad i = \overline{1, n}, i \ne l, i \ne m$

При $i = l$ и учитывая, что $a_{lm} = a_{ml}$ получаем:
$b_{ll} = cd_{ll} + sd_{ml} = c(ca_{ll} + sa_{lm}) + s(ca_{ml} + sa_{mm}) = c^2a_{ll} + 2sca_{lm} + s^2a_{mm}$ 

При $i = m$ имеем:
$b_{lm} = cd_{lm} + sd_{mm} = c(-sa_{ll} + ca_{lm}) + s(-sa_{ml} + ca_{mm}) = sc(a_{mm} - a_{ll} + (c^2 - s^2)a_{lm})$
$b_{mm} = -sd_{lm} + cd_{mm} = -s(-sa_{ll} + ca_{lm}) + c(-sa_{ml} + ca_{mm}) = s^2a_{ll} + -2sca_{lm} + c^2a_{mm}$ 

Ввиду симметричности $B$ формулы выше полностью определяют эту матрицу.

Зададим опорные элементы так, чтобы $b_{lm} = 0$. Тогда
$sc(a_{mm} - a_{ll}) + (c^2 - s^2)a_{lm} = 0$
Подставив $c = \cos \phi, s = \sin \phi$ получим
$\sin \phi \cos \phi (a_{mm} - a_{ll}) = -(\cos^2 \phi - \sin^2 \phi) a_{lm}$
$\dfrac{1}{2}(a_{ll} - a_{mm})\sin 2\phi = a_{lm}\cos 2\phi$
$\tan 2\phi = \dfrac{2a_{lm}}{a_{ll} - a_{mm}} \implies \phi = \dfrac{1}{2}\arctan \left(\dfrac{2a_{lm}}{a_{ll} - a_{mm}}\right)$

Для определённости будем считать $-\dfrac{\pi}{2} \lt 2\phi \le \dfrac{\pi}{2} \implies -\dfrac{\pi}{4} \lt \phi \le \dfrac{\pi}{4}$ 
(и $\phi = \dfrac{\pi}{4}$ при $a_{ll} = a_{mm}$).


# 6. Метод вращения решения проблемы собственных значений. Доказательство сходимости метода~

Для доказательства сходимости метода потребуется следующее утверждение:
$$\underset{i \ne j}\sum b_{ij}^2 \le \left(1 - \dfrac{2}{n(n-1)}\right) \underset{i \ne j}\sum a_{ij}^2$$

При умножении на ортогональную матрицу её евклидова норма не меняется, т. е.
$||B||_E = ||C_{lm}^T AC_{lm}||_E = ||A||_E \implies \sum\limits_{i=1}^n \sum\limits_{j=1}^n b_{ij}^2 = \sum\limits_{i=1}^n \sum\limits_{j=1}^n a_{ij}^2$
Перепишем это равенство в виде:
$\sum\limits_{i \ne j} b_{ij}^2 + \sum\limits_{i=1}^n b_{ii}^2 = \sum\limits_{i \ne j} a_{ij}^2 + \sum\limits_{i=1}^n a_{ii}^2$
$\sum\limits_{i \ne j} b_{ij}^2 - \sum\limits_{i \ne j} a_{ij}^2 = \sum\limits_{i=1}^n a_{ii}^2 - \sum\limits_{i=1}^n b_{ii}^2$
Так как все диагональные элементы, кроме $b_{ll}, b_{mm}$, совпадают с элементами матрицы $A$, то
$\sum\limits_{i \ne j} b_{ij}^2 - \sum\limits_{i \ne j} a_{ij}^2 = a_{ll}^2 + a_{mm}^2 - b_{ll}^2 - b_{mm}^2$

Введём в рассмотрение матрицы


# 7. Метод вращения решения проблемы собственных значений. Оценка точности приближений~
# 8. Метод вращения решения проблемы собственных значений. Определение опорных элементов~
# 9. $QR$ - алгоритм решения проблемы собственных значений. Формулировка теоремы о сходимости~
# 10. Решение частичной проблемы собственных значений. Метод прямых итераций. Метод обратных итераций~